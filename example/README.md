# Run the example

- Ensure that [R](https://www.r-project.org/) and [GNU make](https://www.gnu.org/software/make/) are installed, as well as the [`parallelRemake`](https://github.com/wlandau/parallelRemake) package and its [dependencies](https://github.com/wlandau/parallelRemake/blob/master/DESCRIPTION).
- Run Makefile.R in an R session to generate the [Makefile](https://www.gnu.org/software/make/) and its constituent [`remake`](https://github.com/richfitz/remake)/[YAML](http://yaml.org/) files.
- Open a [command line program](http://linuxcommand.org/) such as [Terminal](https://en.wikipedia.org/wiki/Terminal_%28OS_X%29) and point to the [current working directory](http://www.linfo.org/cd.html).
- Enter `make` into the command line to run the full workflow. To distribute the work over multiple parallel process, you can instead type `make -j <n>` where `<n>` is the number of processes.
- Verify that the generated plot `my_plot.pdf` looks similar to the provided example plot `my_plot.jpg`.
- Optionally, clean up the output. Typing `make clean` removes files generated by `make`, and `make reset` removes those files plus the [Makefile](https://www.gnu.org/software/make/) and [YAML](http://yaml.org/) files generated by `Makefile.R`.


# Details

The  is available for download. In this workflow, I

1. Generate four data frames, each with 1000 rows and columns `x` and `y`.
2. Take the column means of each data frame.
3. Plot the column means as below, where each point corresponds to a data frame.

<div style = "text-align:center">
<img src="my_plot.jpg" width = 375px height = 375px/>
</div>

Normally, this 3-task workflow would be an easy job for [`remake`](https://github.com/richfitz/remake). However, let's say I want run tasks (1) and (2) in parallel processes, with one process per dataset. The [`remake`](https://github.com/richfitz/remake) package does not allow for much parallelism because it runs in a single R session, so I use `parallelRemake` to run pieces of the workflow in parallel instances of [`remake`](https://github.com/richfitz/remake). At the end of this tutorial, you will be able to call `make -j` to distribute the work over multiple parallel processes.

First, let's define the functions for generating data, saving column means, and plotting. I keep them in [`code.R`](https://github.com/wlandau/parallelRemake/blob/master/example/code.R), also below.

```{r}
generate_data = function(){
  data.frame(
    x = rnorm(1000), 
    y = rnorm(1000, mean = 16)
  )
}

my_plot = function(column_means){
  plot(y ~ x, data = do.call(rbind, column_means))
}
```

Next, I generate a [`remake`](https://github.com/richfitz/remake)/[YAML](http://yaml.org/) file for each "step" of the workflow. In this case, I create one [YAML](http://yaml.org/) file (i.e., step) per dataset for tasks (1) and (2) and a single [YAML](http://yaml.org/) file for task (3). I could write these [YAML](http://yaml.org/) files by hand, but for big simulation studies, this is cumbersome and prone to human error. Below, I automate the production of the [YAML](http://yaml.org/) files. Specifically, I use `write_yaml` to produce each [YAML](http://yaml.org/) file from a named list.

```{r}
library(parallelRemake) 

# Encode remake/YAML instructions to generate multiple datasets
# and take the column means of each dataset.
for(rep in 1:4){ 
  dataset = paste0("dataset", rep)  
  column_means = paste0("column_means", rep) 
 
  # Initialize YAML fields.
  fields = list(
    sources = "code.R",
    targets = list(
      all = list(depends = column_means)
    )
  )

  # Add a target to create the data.
  fields$targets[[dataset]] = list(command = strings(generate_data()))

  # Add a target to take the column means of a dataset.
  my_command = paste0("colMeans(dataset", rep, ")")
  fields$targets[[column_means]] = list(command = my_command)

  # Write the YAML file for remake.
  write_yaml(fields, paste0("step", rep, ".yml"))
}

# Write the remake/YAML file for plotting the column means of the datasets
# initialize YAML fields
fields = list(
  sources = "code.R",
  packages = "parallelRemake", # needed for `remember`
  targets = list(
    all = list(depends = "my_plot.pdf"),
    my_plot.pdf = list(
      command = strings(my_plot(column_means)),
      plot = "TRUE"
    ),

    # Remember the column means from the previous instances of remake
    column_means = list(command = strings(
      remember(I("column_means1"), I("column_means2"), I("column_means3"), I("column_means4"))
    ))
  )
)

# Write the plotting YAML file
write_yaml(fields, "my_plot.yml")
```

Above, there are two utility functions useful for the user.

1. `remember` reloads one or more objects from the hidden [`remake`](https://github.com/richfitz/remake) cache. This is particularly useful if you've stopped in the middle of a workflow and you want to check your functions in `code.R`. For example, `remember(dataset1)` returns the object `dataset1` generated previously, and `remember(dataset1, "dataset2")` will return a list containing objects `dataset1` and `dataset2`. If you use `remember` for a command in a [`remake`](https://github.com/richfitz/remake)/[YAML](http://yaml.org/) file, be sure that the return object is not the same name as any of the  arguments, as this will trigger unnecessary rebuilds.
2. `strings` takes general R expressions and converts them into character vectors. Try `strings(one = readRDS("mse.rds"), two = y <- x + 1)`.

Next, I organize the workflow steps (i.e., [YAML](http://yaml.org/) files) into parallelizable stages of the workflow. Within each stage, the steps can be run in separate parallel processes. 

```{r}
stages = list(
  data = paste0("step", 1:reps, ".yml"),
  plot = strings(my_plot.yml)
)
```

In `stages`, I include the `.yml` extensions of the [YAML](http://yaml.org/) files previously generated, but you have the option to omit them. Duplicates are checked after the `.yml` extension are removed. 

This organization of steps into stages is encoded in the overarching [Makefile](https://www.gnu.org/software/make/) produced by `write_makefile`. 

```{r}
write_makefile(stages)
```

With a [Makefile](https://www.gnu.org/software/make/) in hand, I can easily run the whole workflow. First, I open a [command line program](http://linuxcommand.org/) such as [Terminal](https://en.wikipedia.org/wiki/Terminal_%28OS_X%29) and point to the [current working directory](http://www.linfo.org/cd.html). Then, depending on what I type into the command line, I can manage the workflow in the following ways.

- `make` runs the full workflow, only building targets that are out of date.
- `make -j <n>` is the same as above with the workflow distributed over `<n>` parallel processes. Similarly, you can append `-j <n>` to any of the commands below to activate parallelism.
- `make data` just makes the datasets. The [Makefile](https://www.gnu.org/software/make/) knows to do this because `data` is in `names(stages)`.
- `make plot` ensures the datasets are up to date and then makes the plot. The [Makefile](https://www.gnu.org/software/make/) knows to do this because `plot` is in `names(stages)`.
- `make clean` removes the files generated by `make`. If some of your files are produced by side effects, `make clean` might not remove them. In that case, use the `clean` argument of `write_makefile` to add extra shell commands to the `clean` rule.
```{r}
write_makefile(stages, clean = c("rm -f myfile1", "rm -f myfile2"))
```
- `make reset` runs `make clean` and then removes the [Makefile](https://www.gnu.org/software/make/) and all its constituent [YAML](http://yaml.org/) files.
